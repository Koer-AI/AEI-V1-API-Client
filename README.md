# AEI-V1 Emotion Classification API Documentation

This API allows you to classify the emotional content of an audio file. You provide the API with a URL to an audio file hosted on **your own servers or storage**, and the API returns the detected emotion.

--- 
## 1. API Endpoint

To classify emotions, send a `POST` request to the following endpoint:

**`POST https://api.yourcompany.com/v1/classify-emotion`**

--- 
## 2. Authentication

Authentication is required for all requests and is performed by including your credentials in the request headers.

| Header Name   | Type    | Description                                                                                                                                                                                                                                                                                             | Example Value           | Required |
| :------------ | :------ | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------- | :------- |
| `Email`       | `string` | Your registered email address associated with your API account.                                                                                                                                                                                                                                   | `your_email@example.com` | Yes      |
| `Authorization` | `string` | Your unique API Key. This serves as your authentication token. **Security Note:** Ensure your API Key is kept secure and not exposed in client-side code or public repositories.                                                                                                                    | `YOUR_API_KEY_HERE` | Yes      |

--- 
## 3. Request Parameters

The audio file URL must be provided as a query parameter in your `POST` request. This URL should point to the audio file stored within **the client's own database, cloud storage bucket (e.g., GCP, AWS S3), or other web-accessible hosting solution.**

| Parameter Name          | Type    | Description                                                                                                                                                                                                                                                                                                                                                                                                                              | Required |
| :---------------------- | :------ | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------- |
| `audio_path_or_url` | `string` | The URL of the audio file to be classified. This must be either: <br> 1. A **publicly accessible URL** (e.g., hosted on a web server or a public cloud storage bucket). <br> 2. A **temporary signed URL** (generated by your storage provider, allowing secure, time-limited access to a private file). <br> The API will temporarily download the audio from this URL for processing. | Yes      |

--- 
## 4. Response

### Successful Response (Status Code: `200 OK`)

Upon successful processing, the API will return a JSON object containing the detected emotion and other relevant details.

```json
{
  "status": "success",
  "message": "Emotion classification from provided audio file: happy",
  "emotion": "HAPPY",
  "original_url": "[https://example.com/your-audio-file.wav](https://example.com/your-audio-file.wav)",
  "timestamp": "2024-06-21T14:30:00.000Z"
}
```

| Field Name     | Type     | Description                                                                                                        |
| :------------- | :------- | :----------------------------------------------------------------------------------------------------------------- |
| `status`       | `string` | Indicates the success of the request. Will be `"success"` for a valid response.                                      |
| `message`      | `string` | A human-readable message describing the classification result.                                                     |
| `emotion`      | `string` | The primary emotion detected in the audio (e.g., "happy", "angry", "sad", "neutral", "surprise", "disgust", "fear"). |
| `original_url` | `string` | The URL of the audio file that was processed by the API.                                                           |
| `timestamp`    | `string` | The UTC timestamp when the request was processed.                                                                  |

### Error Responses

The API will return standard HTTP status codes along with a JSON body providing details about the error.

```json
{
  "status": "error",
  "message": "Authentication failed: Invalid API Key or Email.",
  "code": 401
}
```

| Field Name | Type     | Description                                                          |
| :--------- | :------- | :------------------------------------------------------------------- |
| `status`   | `string` | Indicates an error. Will be `"error"`.                               |
| `message`  | `string` | A human-readable message describing the error.                       |
| `code`     | `integer` | The HTTP status code associated with the error (e.g., 400, 401, 500). |

**Common Error Codes:**

* **`400 Bad Request`**: The request was malformed, or the `audio_path_or_url` was invalid or inaccessible.
* **`401 Unauthorized`**: Missing or invalid `Email` or `Authorization` header.
* **`500 Internal Server Error`**: An unexpected error occurred on the API server.

--- 
## 5. Code Example (Python)

Below is a Python example demonstrating how to make a request to the AEI-V1 API.


```python
import requests
import time
import os

# --- IMPORTANT: REPLACE WITH YOUR ACTUAL VALUES ---
# This URL should point to your own hosted audio file (public or temporary signed).
AUDIO_FILE_URL = "YOUR_PUBLIC_OR_SIGNED_AUDIO_FILE_URL_HERE"
YOUR_EMAIL = "your_registered_email@example.com"
YOUR_API_KEY = "YOUR_API_KEY_HERE" # Replace with your actual API key
# ---------------------------------------------------

# AEI-V1 API Endpoint (Pseudo Endpoint for documentation)
AEI_V1_API_ENDPOINT = "https://api.yourcompany.com/v1/classify-emotion" # Your actual API endpoint goes here

# Prepare headers for authentication
headers = {
    "Email": YOUR_EMAIL,
    "Authorization": YOUR_API_KEY
}

print(f"\nSending request to AEI-V1 API...")
print(f"Headers: {headers}")
print(f"Audio URL: {AUDIO_FILE_URL}")

# Make the POST request with the audio URL as a query parameter
response = requests.post(
    AEI_V1_API_ENDPOINT,
    headers=headers,
    params={"audio_path_or_url": AUDIO_FILE_URL}
)

# Process the response
if response.status_code == 200:
    print("\n--- API Response (Success) ---")
    print(response.json())
else:
    print(f"\n--- API Error (Status Code: {response.status_code}) ---")
    print("Response Text:", response.text)
    try:
        print("Response JSON:", response.json())
    except requests.exceptions.JSONDecodeError:
        pass # Not a JSON response, just print text
```

---
### 6. Code Example (JavaScript)
Below is a JavaScript example demonstrating how to make a request to the AEI-V1 API.


```python
// --- IMPORTANT: REPLACE WITH YOUR ACTUAL VALUES ---
// This URL should point to your own hosted audio file (public or temporary signed).
const AUDIO_FILE_URL = "YOUR_PUBLIC_OR_SIGNED_AUDIO_FILE_URL_HERE"; // e.g., "https://example.com/audio/sample.mp3"
const YOUR_EMAIL = "your_registered_email@example.com"; // e.g., "johndoe@example.com"
const YOUR_API_KEY = "YOUR_API_KEY_HERE"; // Replace with your actual API key, e.g., "sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
// ---------------------------------------------------

// AEI-V1 API Endpoint
// Your actual API endpoint goes here.
const AEI_V1_API_ENDPOINT = "https://api.yourcompany.com/v1/classify-emotion";

/**
 * Sends a POST request to the Emotion Classification API.
 * @returns {Promise<object|string>} A promise that resolves with the JSON response
 * or rejects with an error message.
 */
async function classifyEmotion() {
    console.log("\nSending request to AEI-V1 API...");
    console.log(`Email: ${YOUR_EMAIL}`);
    console.log(`Audio URL: ${AUDIO_FILE_URL}`);

    try {
        // Construct URL with query parameter
        const url = new URL(AEI_V1_API_ENDPOINT);
        url.searchParams.append("audio_path_or_url", AUDIO_FILE_URL);

        // Prepare headers for authentication
        const headers = {
            "Email": YOUR_EMAIL,
            "Authorization": YOUR_API_KEY,
        };

        // Make the POST request using fetch
        const response = await fetch(url.toString(), {
            method: 'POST',
            headers: headers
        });

        // Process the response
        if (response.ok) { // Check if status code is 2xx
            console.log("\n--- API Response (Success) ---");
            const jsonResponse = await response.json();
            console.log(jsonResponse);
            return jsonResponse; // Return the JSON response
        } else {
            const errorText = await response.text();
            let errorMessage = `API Error (Status Code: ${response.status || 'Unknown'}): \n`;
            try {
                const errorJson = JSON.parse(errorText);
                errorMessage += `Details: ${JSON.stringify(errorJson, null, 2)}`;
            } catch (e) {
                errorMessage += `Raw Response: ${errorText}`;
            }
            console.error(errorMessage);
            throw new Error(errorMessage); // Throw an error for non-2xx responses
        }
    } catch (error) {
        console.error("\n--- Network or Request Error ---");
        console.error("Error:", error);
        throw new Error(`An unexpected error occurred: ${error.message}`); // Re-throw network errors
    }
}

// Example of how to call the function (for documentation purposes)
// You would typically call this in your application logic.
// classifyEmotion()
//     .then(result => {
//         console.log("Function call successful:", result);
//         // Handle the successful classification result here
//     })
//     .catch(error => {
//         console.error("Function call failed:", error);
//         // Handle errors during classification here
//     });

```

--- 
## 7. Important Operational Notes for Developers

* **Audio File Accessibility & Hosting:** The `audio_path_or_url` passed to the API **must be a publicly accessible URL or a temporary signed URL.** **You, the client, are solely responsible for hosting this audio file** and ensuring it remains accessible to our API for the duration of processing.

* **Your Responsibilities for a Successful Request:** As the client, your primary responsibilities are to:
    * Host your audio file securely and provide a valid, accessible URL.
    * Include your correct `Email` and `Authorization` (API Key) in the request headers.
    * Send a `POST` request to the specified API endpoint.

* **Internal Our Server-Side Permissions:** Our internal configurations are equipped with all the necessary permissions to access secrets, storage, and other required services. This is handled entirely on our end and **does not require any action or special permissions from your client application.**

* **Internal Authentication for File Upload (Not for Client):** Our internal development scripts require authentication to upload local files to our cloud storage. This is an internal operational detail related to our testing and **does not affect the client**. Since clients will be providing their own externally hosted audio file URLs, you will not need to manage upload permissions to use this API.

---
## 8. Data Storage and Advanced Analytics

Since our API returns emotion classifications as simple strings, you can **easily store these in your central database.**

To unlock deeper insights into the emotional dynamics of your user base through advanced visualizations, charts, and comprehensive reporting, consider our `Enterprise Tier`. This tier offers significantly higher API call volumes and includes access to a specialized backend API and interactive web-application for data visualization.

---

# DEMO: Integrating Emotion Recognition into a Survey Tool

### Integrating Voice Emotion API into a Survey Portal
Integrating a voice emotion API into a survey portal involves capturing audio from survey participants, sending that audio to the API for analysis, and then incorporating the emotional insights into your survey data.

### Prerequisites (Client's Responsibilities):

Before diving in, your client will need to have the following in place:

1.  **A Web-Based Survey Tool:** Their custom survey application, including both frontend and backend components.
2.  **Audio Recording Capability:** The ability to record audio directly from the user's browser (typically using the HTML5 MediaRecorder API).
3.  **Cloud Storage:** A secure cloud storage solution (e.g., their own GCP bucket, AWS S3 bucket, Azure Blob Storage) to store the recorded audio files.
4.  **Backend Server:** A server-side component (e.g., Node.js, Python Flask/Django, Ruby on Rails, PHP) that can handle audio file uploads, generate secure URLs for the stored audio, and make external API calls.
5.  **Your AEI-V1 API Credentials:** Their unique `Email` and `API Key` obtained after subscribing to your service.

### Integration Steps:

#### Step 1: User Records Audio in the Survey Tool (Client-Side Frontend)

The initial step involves capturing audio responses directly from your survey participants' web browsers. This is achieved using a self-contained HTML and JavaScript snippet that accesses the user's microphone to record their input. This solution requires no external frameworks or complex build processes, making it straightforward to integrate into existing web pages.

The code provides a complete client-side interface for recording, playing back, and downloading audio, along with basic user feedback and error handling.


```python
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio Recorder Example</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body { font-family: 'Inter', sans-serif; }
    </style>
</head>
<body class="bg-gray-100 flex items-center justify-center min-h-screen p-4">
    <div class="bg-white p-8 rounded-lg shadow-lg max-w-lg w-full text-center">
        <h1 class="text-3xl font-bold text-gray-800 mb-6">Audio Recorder</h1>

        <div class="flex justify-center space-x-4 mb-8">
            <button id="recordButton" class="bg-green-600 hover:bg-green-700 text-white font-semibold py-3 px-6 rounded-lg shadow-md transition duration-300 ease-in-out transform hover:scale-105">
                Start Recording
            </button>
            <button id="stopButton" disabled class="bg-red-600 hover:bg-red-700 text-white font-semibold py-3 px-6 rounded-lg shadow-md transition duration-300 ease-in-out transform hover:scale-105 opacity-50 cursor-not-allowed">
                Stop Recording
            </button>
        </div>

        <audio id="audioPlayback" controls class="w-full h-12 mb-6 rounded-md shadow-inner bg-gray-200"></audio>

        <a id="downloadLink" style="display:none;" class="inline-block bg-blue-600 hover:bg-blue-700 text-white font-semibold py-2 px-5 rounded-lg shadow-md transition duration-300 ease-in-out transform hover:scale-105 no-underline">
            Download Audio
        </a>

        <div id="messageBox" class="hidden mt-6 p-3 rounded-md text-sm"></div>
    </div>

    <script>
        let mediaRecorder;
        let audioChunks = [];
        let mediaStream;

        const recordButton = document.getElementById('recordButton');
        const stopButton = document.getElementById('stopButton');
        const audioPlayback = document.getElementById('audioPlayback');
        const downloadLink = document.getElementById('downloadLink');
        const messageBox = document.getElementById('messageBox');

        // Updates button states and styling
        const updateButtonStates = (isRecording) => {
            recordButton.disabled = isRecording;
            stopButton.disabled = !isRecording;
            recordButton.classList.toggle('opacity-50', isRecording);
            recordButton.classList.toggle('cursor-not-allowed', isRecording);
            stopButton.classList.toggle('opacity-50', !isRecording);
            stopButton.classList.toggle('cursor-not-allowed', !isRecording);
        };

        // Displays a message to the user
        const showMessage = (msg, type) => {
            messageBox.textContent = msg;
            messageBox.classList.remove('hidden', 'bg-green-100', 'text-green-800', 'bg-red-100', 'text-red-800', 'bg-blue-100', 'text-blue-800');
            if (type === 'success') messageBox.classList.add('bg-green-100', 'text-green-800');
            else if (type === 'error') messageBox.classList.add('bg-red-100', 'text-red-800');
            else messageBox.classList.add('bg-blue-100', 'text-blue-800');
            messageBox.classList.remove('hidden');
        };

        recordButton.onclick = async () => {
            messageBox.classList.add('hidden');
            audioChunks = [];
            audioPlayback.src = '';
            downloadLink.style.display = 'none';

            try {
                mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(mediaStream);

                mediaRecorder.ondataavailable = event => {
                    if (event.data.size > 0) audioChunks.push(event.data);
                };

                mediaRecorder.onstop = () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    const audioUrl = URL.createObjectURL(audioBlob);
                    audioPlayback.src = audioUrl;
                    downloadLink.href = audioUrl;
                    downloadLink.download = 'recorded_audio.webm';
                    downloadLink.style.display = 'inline-block';
                    showMessage('Recording finished!', 'success');
                    mediaStream.getTracks().forEach(track => track.stop()); // Stop microphone
                };

                mediaRecorder.start();
                updateButtonStates(true);
                showMessage('Recording started...', 'info');

            } catch (error) {
                console.error('Mic error:', error);
                if (error.name === 'NotAllowedError' || error.name === 'PermissionDeniedError') {
                    showMessage('Microphone access denied. Allow permissions.', 'error');
                } else {
                    showMessage(`Error: ${error.message}`, 'error');
                }
                updateButtonStates(false);
            }
        };

        stopButton.onclick = () => {
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
            }
            updateButtonStates(false);
        };

        document.addEventListener('DOMContentLoaded', () => updateButtonStates(false));
    </script>
</body>
</html>

```


    Running cells with '/opt/homebrew/bin/python3' requires ipykernel package.


    Run the following command to install 'ipykernel' into the Python environment. 


    Command: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'


### 2. Secure Audio Storage

Once audio is captured, it needs to be stored securely and be accessible by the API. Your server-side code (e.g., Node.js, Python, PHP) will handle receiving the audio blob from the frontend and uploading it to a cloud storage service.


```python
# Example: Python Flask endpoint for receiving audio and uploading to S3 (pseudo-code)
from flask import Flask, request, jsonify
import boto3
import os
import uuid

app = Flask(__name__)

# Configure your S3 client
s3 = boto3.client(
    's3',
    aws_access_key_id=os.environ.get('AWS_ACCESS_KEY_ID'),
    aws_secret_access_key=os.environ.get('AWS_SECRET_ACCESS_KEY')
)
S3_BUCKET_NAME = 'your-audio-survey-bucket'

@app.route('/upload-audio', methods=['POST'])
def upload_audio():
    if 'audio' not in request.files:
        return jsonify({"error": "No audio file provided"}), 400

    audio_file = request.files['audio']
    if audio_file.filename == '':
        return jsonify({"error": "No selected file"}), 400

    # Generate a unique filename
    filename = f"survey_audio/{uuid.uuid4()}.webm"

    try:
        s3.upload_fileobj(audio_file, S3_BUCKET_NAME, filename)
        # Construct the public URL or a signed URL
        audio_url = f"https://{S3_BUCKET_NAME}.s3.amazonaws.com/{filename}"
        # For signed URLs, you'd generate one:
        # audio_url = s3.generate_presigned_url('get_object', Params={'Bucket': S3_BUCKET_NAME, 'Key': filename}, ExpiresIn=3600) # URL valid for 1 hour

        return jsonify({"message": "Audio uploaded successfully", "audio_url": audio_url}), 200
    except Exception as e:
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    app.run(debug=True)
```

### 3. API Integration (Backend)

The core logic for sending the audio to the emotion API and receiving results should reside in your survey portal's backend. This part uses the Python code you provided.


```python
import requests
import os

def classify_emotion_from_audio(audio_file_url: str, your_email: str, your_api_key: str) -> dict:
    """
    Sends an audio file URL to the voice emotion API for classification.

    Args:
        audio_file_url: The public or signed URL of the audio file.
        your_email: Your registered email for API authentication.
        your_api_key: Your API key for authentication.

    Returns:
        A dictionary containing the API response (emotion classification) or an error.
    """
    # --- IMPORTANT: REPLACE WITH YOUR ACTUAL VALUES ---
    AEI_V1_API_ENDPOINT = "https://api.yourcompany.com/v1/classify-emotion" # Your actual API endpoint goes here
    # ---------------------------------------------------

    headers = {
        "Email": your_email,
        "Authorization": your_api_key
    }

    print(f"\nSending request to AEI-V1 API...")
    print(f"Headers: {headers}")
    print(f"Audio URL: {audio_file_url}")

    try:
        response = requests.post(
            AEI_V1_API_ENDPOINT,
            headers=headers,
            params={"audio_path_or_url": audio_file_url}
        )

        if response.status_code == 200:
            print("\n--- API Response (Success) ---")
            return response.json()
        else:
            print(f"\n--- API Error (Status Code: {response.status_code}) ---")
            print("Response Text:", response.text)
            try:
                print("Response JSON:", response.json())
                return {"error": response.json()}
            except requests.exceptions.JSONDecodeError:
                return {"error": response.text}
    except requests.exceptions.RequestException as e:
        print(f"\n--- Network/Request Error ---")
        print(e)
        return {"error": str(e)}

# --- Example Usage (to be integrated after audio upload) ---
if __name__ == "__main__":
    # This would typically be the URL returned from your audio upload service
    SAMPLE_AUDIO_URL = "YOUR_PUBLIC_OR_SIGNED_AUDIO_FILE_URL_HERE"
    YOUR_EMAIL_CONFIG = os.environ.get("YOUR_API_EMAIL", "your_registered_email@example.com")
    YOUR_API_KEY_CONFIG = os.environ.get("YOUR_API_KEY", "YOUR_API_KEY_HERE")

    if SAMPLE_AUDIO_URL != "YOUR_PUBLIC_OR_SIGNED_AUDIO_FILE_URL_HERE" and \
       YOUR_EMAIL_CONFIG != "your_registered_email@example.com" and \
       YOUR_API_KEY_CONFIG != "YOUR_API_KEY_HERE":
        emotion_result = classify_emotion_from_audio(
            SAMPLE_AUDIO_URL,
            YOUR_EMAIL_CONFIG,
            YOUR_API_KEY_CONFIG
        )
        print("\nEmotion Classification Result:", emotion_result)
    else:
        print("\nPlease configure SAMPLE_AUDIO_URL, YOUR_EMAIL_CONFIG, and YOUR_API_KEY_CONFIG for testing.")
```

### 4. Data Integration and Reporting

Finally, integrate the emotion analysis results into your survey data. Store the emotion classifications alongside the participant's other survey responses.


```python
# Example: Pseudo-code for storing emotion data in a database
def save_survey_response_with_emotion(
    survey_id: str,
    participant_id: str,
    question_id: str,
    audio_url: str,
    emotion_data: dict
):
    """
    Saves the survey response along with the emotion classification data to your database.
    """
    # This would involve your ORM or direct database calls (e.g., SQLAlchemy, Django ORM)
    print(f"Saving response for Survey: {survey_id}, Participant: {participant_id}")
    print(f"Question: {question_id}, Audio URL: {audio_url}")
    print(f"Emotion Data: {emotion_data}")

    # Example: In a SQL database, you might have a table like:
    # CREATE TABLE survey_responses (
    #     id INT PRIMARY KEY AUTO_INCREMENT,
    #     survey_id VARCHAR(255),
    #     participant_id VARCHAR(255),
    #     question_id VARCHAR(255),
    #     audio_url TEXT,
    #     dominant_emotion VARCHAR(50),
    #     emotion_scores JSON, -- Store full JSON for detailed analysis
    #     timestamp DATETIME
    # );

    # Logic to insert/update your database
    # For example:
    # db_connection.execute(
    #     "INSERT INTO survey_responses (survey_id, participant_id, question_id, audio_url, dominant_emotion, emotion_scores, timestamp) VALUES (?, ?, ?, ?, ?, ?, NOW())",
    #     (survey_id, participant_id, question_id, audio_url, emotion_data.get('dominant_emotion'), json.dumps(emotion_data),)
    # )
    print("Data saved to database (pseudo-code).")

# Example of how you'd call this after API classification
if __name__ == "__main__":
    # Assuming you have the emotion_result from classify_emotion_from_audio
    # and other survey context
    sample_emotion_result = {
        "dominant_emotion": "HAPPY",
    }

    if sample_emotion_result:
        save_survey_response_with_emotion(
            survey_id="SURVEY_XYZ",
            participant_id="PARTICIPANT_123",
            question_id="Q_AUDIO_1",
            audio_url="https://your-s3-bucket/survey_audio/12345.webm",
            emotion_data=sample_emotion_result
        )
```
